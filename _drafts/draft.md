---
layout: post
title:  "홉필드 모델 실습"
subtitle:  "인공지능"
date:   2030-01-01 12:00:00 +0900 # release.sh 사용시 자동 입력 될것임
author:     "날도"
header-img: "img/post-bg-2015.jpg"
mathjax: true
tags: 
    - 인공지능
    - 머신러닝
    - 과제
lastmod : 2019-04-03 12:00:00
sitemap :
    changefreq : daily
    priority : 1.0
---
인공지능수업 과제로 홉필드 모델에 대한 실습 레포트 작성을 진행하게 되었다.

## 홉필드 모델이란?
홉필드 모델은 1982년 미국의 물리학자 Hopfield가 발표한 네트워크 모델이다. 홉필드 모델의 기본 가정(제약조건이라고도 한다) 은 노드간의 결합 강도, 즉 가중치가 대칭적이고, 비동기적으로 동작하는 병렬 컴퓨터 모델이라고 한다. 노드간의 결합강도가 같기 때문에 완전 연결된 홉필드 모델의 구조를 아래와 같이 나타낼 수 있다.

![(완전연결된 홉필드 이미지 구조)](/img/in-post/post-hopfieldnetwork/1.png)

신경계에서 뉴런의 특징은 자극이 임계치가 넘으면 흥분하고, 그 이하는 억제된다. 홉필드 모델은 이러한 특성을 모방하기 위해 Hard limt non-linearity function을 사용하였는데, 이 함수는 입력값이 양수면 +1, 음수면 -1인 소위 계단함수를 사용하고 있다.

![(계단함수 이미지)](/img/in-post/post-hopfieldnetwork/2.png)
<br><br>
$$ 
Y^{sign}
\begin{cases} 
+1,  & \text{if $X > 0$} \\
-1, & \text{if $X < 0$} \\
0, & \text{if $X == 0$}
\end{cases}
$$

위는 단순화 한 수식이다.<br>
홉필드 네트워크는 이러한 단순 임계값 이론에 기초하고 있으며, 이는 연상기억 문제의 최적화에 아주 유용하다.


## 연상 메모리
연상메모리는 딥러닝의 기초로 생각하고 있다. 인간의 관점에서, 우리는 지금까지 자라오며 어떠한 "물건"에 대해서 학습해왔다. 예를 들어, 사과그림을 보면 사과를 떠오른다던지. 또한 그렇게 사과 이미지를 알고 있기 때문에, 인간은 사과의 이미지 일부만 봐도 사과인 것을 알아본다. <br>
기계의 관점에서 학습이란 _가중치(weight 값)를 조절하는 과정_ 이며, 외부에서 교사신호(Teaching Input)로써 입력신호에 대한 정답출력을 주는 학습방법인 **교사학습**(Supervised Learning)과 일일이 교사 신호를 주지 않는 학습방법인 **무교사학습**(Unsupervised Learning)이 있다.

$$ 
E(t) = -\frac12\sum_{i \ne j}w_{ij}o_io_j(t) - \sum_i\theta_io_i(t) \text{($\theta:임계값$)}
$$

~~자세한 수식 설명은 생략하고 싶다... 수식만 보면 머리가 아퍼~~

위의 수식은 연상메모리를 에너지 개념으로 설명한 수식이며, $o_i$는 노드의 출력을 의미하며 0 또는 1의 값을 취하고, $\theta$는 임계값을 의미한다. $E$는 발산되는 에너지 값이다.<br>
이 수식을 그래프로 표현하면 아래와 같다.

![(홉필드 모델 그래프)](/img/in-post/post-hopfieldnetwork/3.png)

위 그림에서 x축은 상태, 즉 i,j 값을 나타내며, y축은 발산되는 에너지 양을 나타낸다. 상태가 전진됨에 따라가다보면 최소점을 찾을 수가 있는데, 이를 **극소점**이라 한다. 우리는 가중치 값 $w_{ij}$과 임계점 $\theta$을 이용하여 이 극소점을 찾는것을 목표로 한다. 즉 발산되는 에너지가 최소되는 지점을 찾기 위해 상태를 전진시키는 "**학습**"이 필요하다. 만약 학습이 충분히 되지 않는다면 A라는 최소점을 두고서도 B라는 최소점에서 만족해버릴지도 모르기 때문이다. 이 최소점을 찾아나서는 과정에서 $w_{ij}$을 조정하는 것이 바로 학습이다. 만약 $w_{ij}$이 더 이상 변하지 않는다면 그 시점에서 학습은 종료된다. ~~이론상으로는...~~

## 연상 메모리 구현
이제 본방인 연상메모리 구현을 파이썬으로 구현해 보았다.<br>
실습 내용은 10x10 픽셀로 된 한글 14글자의 패턴을 학습시켜 임의의 입력값에 대해 출력값을 수정하는 연상메모리 구현이다.<br>
처음에는 '가'부터 '하'까지 14글자를 학습시키려 했으나, 모음 'ㅏ'가 계속 중복되는게 거슬려서 모음 순서도 진행시키로 했다.<br>
즉 아래와 같은 글자를 학습시킨다.<br>
**가, 내, 댜, 럐, 머, 베, 셔, 예, 조, 쵸, 쿠, 튜, 프, 히**

써놓고 보니 웃기긴 한데, 위의 학습이 제대로만 된다면 모든 한글 음절에 대해서 학습도 가능할 것이다.<br>

![(한글글자 모임)](/img/in-post/post-hopfieldnetwork/4.png)

파이썬 소스코드는 다음과 같다.

> 이미지 출처 : <http://www.aistudy.co.kr/neural/hopfield_kim.htm>
